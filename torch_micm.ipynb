{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable\n",
    "\n",
    "from bidict import bidict\n",
    "import networkx as nx\n",
    "import network_diffusion as nd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_p = nd.mln.functions.get_toy_network_piotr()\n",
    "print(net_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_m = nd.MultilayerNetwork.from_nx_layer(nx.les_miserables_graph(), [\"l1\", \"l2\", \"l3\"])\n",
    "print(net_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mln_for_conversion(net: nd.MultilayerNetwork) -> tuple[nd.MultilayerNetwork, bidict, dict[str, set[Any]] | None]:\n",
    "    \"\"\"\n",
    "    Prepare nd.MultilayerNetwork for conversion to torch representation.\n",
    "\n",
    "    If net is not multiplex, then multiplicity actoss all layers is imposed. Names of actors are\n",
    "    converted to integers.\n",
    "\n",
    "    :param net: a multilayer network to prepare for conversion\n",
    "    :return: a new instance of nd.MultilayerNetwork prepared for conversion, a bi-directional map of\n",
    "        old and new names of the actors, a dict of sets of nodes added to make the net multiplex\n",
    "    \"\"\"\n",
    "    if not net.is_multiplex():\n",
    "        net, added_nodes = net.to_multiplex()\n",
    "    else:\n",
    "        net, added_nodes = net.copy(), None\n",
    "    # ac_map = {ac.actor_id: idx for idx, ac in enumerate(sorted(net.get_actors(), key=lambda x: x.actor_id))}\n",
    "    ac_map = {ac.actor_id: idx for idx, ac in enumerate(net.get_actors())}\n",
    "    for l_graph in net.layers.values():\n",
    "        nx.relabel_nodes(l_graph, mapping=ac_map, copy=False)\n",
    "    return net, bidict(ac_map), added_nodes\n",
    "\n",
    "\n",
    "def coalesce_and_check(tensor_raw: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Coalesce tensor and check if anything chenged during that operation.\"\"\"\n",
    "    tensor_coalesced = tensor_raw.coalesce()\n",
    "    assert torch.all(tensor_raw._indices() == tensor_coalesced._indices())\n",
    "    assert torch.all(tensor_raw._values() == tensor_coalesced._values())\n",
    "    assert tensor_raw.size() == tensor_coalesced.size()\n",
    "    assert tensor_raw._nnz() == tensor_coalesced._nnz()\n",
    "    assert tensor_raw.layout == tensor_coalesced.layout\n",
    "    return tensor_coalesced\n",
    "\n",
    "\n",
    "def mln_to_sparse(net: nd.MultilayerNetwork, actor_order: list[int]) -> tuple[torch.Tensor, list[str]]:\n",
    "    \"\"\"\n",
    "    Converse nd.MultilayerNetwork to an adjacency matrix as a tensor. \n",
    "\n",
    "    :param net: nd.MultilayerNetwork to be converted, must be multiplex and have actors' ids as ints\n",
    "    :param actor_order: order of actors' ids to be used in the output adjacency tensor\n",
    "    :return: an adj. matrix as a sparse tensor and a list of layer names ordered as in adj. matrix\n",
    "    \"\"\"\n",
    "    A, L = [], []\n",
    "    for l_name, l_graph in net.layers.items():\n",
    "        A_idx, A_val = pyg.utils.from_scipy_sparse_matrix(nx.adjacency_matrix(l_graph, actor_order))\n",
    "        l_A = torch.sparse_coo_tensor(indices=A_idx, values=A_val, size=[len(actor_order)] * 2, is_coalesced=True, check_invariants=True)\n",
    "        A.append(l_A)\n",
    "        L.append(l_name)\n",
    "    return coalesce_and_check(torch.stack(A)), L\n",
    "\n",
    "\n",
    "def create_nodes_mask(\n",
    "        layers_order: list[str], actors_map: bidict, nodes_added: dict[str, set[Any]] | None\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create mask with nodes added artifically (while converting network to multiplex) marked as ones.\n",
    "\n",
    "    :param layers_order: names of layers in an order that is preserved in A\n",
    "    :param actors_map: map of actor names Any -> int between original network and its sparse repr\n",
    "    :param nodes_added: a dict of sets of nodes added to make the net multiplex\n",
    "    :return: tensor of states\n",
    "    \"\"\"\n",
    "    nodes_mask = torch.zeros([len(layers_order), len(actors_map)])\n",
    "    if not nodes_added:\n",
    "        return nodes_mask\n",
    "    for l_name, l_added_nodes in nodes_added.items():\n",
    "        # print(f\"layer: {l_name}, idx: {net.L.index(l_name)}, added nodes: {l_added_nodes}\")\n",
    "        for l_added_node in l_added_nodes:\n",
    "            # print(f\"map: {l_added_node}->{net.C[l_added_node]}\")\n",
    "            nodes_mask[layers_order.index(l_name), actors_map[l_added_node]] = 1. # -1 * float(\"inf\")\n",
    "    return nodes_mask\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MultilayerNetworkTorch:\n",
    "    \"\"\"Representation of nd.MultilayerNetwork in a tensor notation.\"\"\"\n",
    "\n",
    "    adjacency_tensor: torch.Tensor  # adjacency matrix as a sparse tensor\n",
    "    layers_order: list[str]  # names of layers in an order that is preserved in adjacency_tensor\n",
    "    actors_map: bidict  # map of actor names Any -> int between the original network and its sparse repr\n",
    "    nodes_mask: torch.Tensor  # mask of nodes added while making the network multiplex ordered in the same way as the nodes in adjacency_tensor\n",
    "\n",
    "    @classmethod\n",
    "    def from_mln(cls, net: nd.MultilayerNetwork) -> \"MultilayerNetworkTorch\":\n",
    "        \"\"\"Represent net as in a tensor notation.\"\"\"\n",
    "        net_converted, ac_map, nodes_added = prepare_mln_for_conversion(net=net)\n",
    "        adj, l_order = mln_to_sparse(net=net_converted, actor_order=list(ac_map.values()))\n",
    "        n_mask = create_nodes_mask(layers_order=l_order, actors_map=ac_map, nodes_added=nodes_added)\n",
    "        return cls(adjacency_tensor=adj, layers_order=l_order, actors_map=ac_map, nodes_mask=n_mask)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__} at {id(self)}\\n\" \\\n",
    "            f\"A: {self.adjacency_tensor}\\n L: {self.layers_order}\\n C: {self.actors_map}\\n S: {self.nodes_mask}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_raw = net_p\n",
    "nd.mln.functions.draw_mln(net_raw, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_converted, ac_map, nodes_added = prepare_mln_for_conversion(net_raw)\n",
    "nd.mln.functions.draw_mln(net_converted, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_tensor, layers_order = mln_to_sparse(net_converted, list(ac_map.values()))\n",
    "adjacency_tensor.to_dense(), layers_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultilayerNetworkTorch.from_mln(net=net_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states_tensor(mln_torch: MultilayerNetworkTorch, seed_set: set[Any]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create tensor of states\n",
    "\n",
    "    :param mln_torch: a network (in tensor representation) to create a states tensor for\n",
    "    :param seed_set: a set of initially active actors (ids of actors given in the original form)\n",
    "    :return: a tensor shaped as [number_of_layers x number_of_actors] with 1. marked for seed nodes\n",
    "        and -inf for nodes that were artifically added during converting the network to the tensor\n",
    "        representation\n",
    "    \"\"\"\n",
    "    seed_set_mapped = [mln_torch.actors_map[seed] for seed in seed_set]\n",
    "    print(f\"{seed_set} -> {seed_set_mapped}\")\n",
    "    states_raw = torch.clone(mln_torch.nodes_mask)\n",
    "    states_raw[states_raw == 1.] = -1 * float(\"inf\")\n",
    "    states_raw[:, seed_set_mapped] += 1\n",
    "    return states_raw\n",
    "\n",
    "\n",
    "def draw_live_edges(A: torch.Tensor, p: float) -> torch.Tensor:\n",
    "    \"\"\"Draw eges which transmit the state (i.e. their random weight < p).\"\"\"\n",
    "    raw_signals = torch.rand_like(A.values(), dtype=float)\n",
    "    thre_signals = (raw_signals < p).to(float)\n",
    "    T = torch.sparse_coo_tensor(indices=A.indices(), values=thre_signals)\n",
    "    assert A.shape == T.shape\n",
    "    assert ((A - T).to_dense() < 0).sum() == 0\n",
    "    return T\n",
    "\n",
    "\n",
    "def mask_S_from(S: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Create mask for T which discards signals from nodes which state != 1.\"\"\"\n",
    "    return (S > 0).to(torch.int).unsqueeze(-1).repeat(1, 1, S.shape[1]).to_sparse_coo()\n",
    "\n",
    "\n",
    "def mask_S_to(S:torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Create mask for T which discards signals to nodes which state != 0.\"\"\"\n",
    "    return torch.abs(torch.abs(S) - 1).to_sparse_coo()\n",
    "\n",
    "\n",
    "def get_active_nodes(T: torch.Tensor, S: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Obtain newly active nodes (0 -> 1) in the current simulation step.\"\"\"\n",
    "    S_f = mask_S_from(S)\n",
    "    S_t = mask_S_to(S)\n",
    "    S_new = ((T * S_f).sum(dim=1) * S_t).to_dense()\n",
    "    assert torch.all(S[S_new.to(torch.int).to(bool)] == 0) == torch.Tensor([True]), \\\n",
    "        \"Some nodes were activated against rules (i.e. only these with state 0 can be activated)!\"\n",
    "    return S_new\n",
    "\n",
    "\n",
    "def protocol_AND(S_raw: torch.Tensor, net: MultilayerNetworkTorch) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Aggregate positive impulses from the layers using AND strategy.\n",
    "\n",
    "    :param S_raw: raw impulses obtained by the nodes\n",
    "    :param net: a network which is a medium for the diffusion\n",
    "    :return: a tensor shaped as [1 x number of actors] with 1. denoting actors that were activated \n",
    "        in this simulation step and 0. denoting actors that weren't activated\n",
    "    \"\"\"\n",
    "    return (S_raw + net.nodes_mask > 0).all(dim=0).to(torch.float)\n",
    "\n",
    "\n",
    "def protocol_OR(S_raw: torch.Tensor, net: MultilayerNetworkTorch) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Aggregate positive impulses from the layers using AND strategy.\n",
    "\n",
    "    :param S_raw: raw impulses obtained by the nodes\n",
    "    :param net: a network which is a medium for the diffusion\n",
    "    :return: a tensor shaped as [1 x number of actors] with 1. denoting actors that were activated \n",
    "        in this simulation step and 0. denoting actors that weren't activated\n",
    "    \"\"\"\n",
    "    return (S_raw > 0).any(dim=0).to(torch.float)\n",
    "\n",
    "\n",
    "def decay_active_nodes(S: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Change states of nodes that are active to become activated (1 -> -1).\"\"\"\n",
    "    decayed_S = -1. * torch.abs(S)\n",
    "    decayed_S[decayed_S == -0.] = 0.\n",
    "    return decayed_S\n",
    "\n",
    "\n",
    "def simulation_step(net: MultilayerNetworkTorch, p: float, protocol: Callable, S0: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Make a single simulation step.\n",
    "    \n",
    "    1. determine which edges drawn value below p\n",
    "    2. transfer state from active (1.) nodes to their inactive (0.) neighbours only if egdes were preserved at step 1.\n",
    "    3. aggregate positive impulses from the layers to determine actors that got activated during this simulation step \n",
    "    4. decay activation potential for actors that were acting as the active in the current simulation step\n",
    "    5. obtain the final tensor of states after this simulation step \n",
    "\n",
    "    :param net: a network wtihch is a medium of the diffusion\n",
    "    :param p: a probability of activation between active and inactive node\n",
    "    :param protocol: a function that aggregates positive impulses from the network's layers\n",
    "    :param S0: initial tensor of nodes' states (0 - inactive, 1 - active, -1 - activated, -inf - node does not exist)\n",
    "    :return: updated tensor with nodes' states\n",
    "    \"\"\"\n",
    "    T = draw_live_edges(net.adjacency_tensor, p)\n",
    "    S1_raw = get_active_nodes(T, S0)\n",
    "    S1_aggregated = protocol(S_raw=S1_raw, net=net)\n",
    "    S0_decayed = decay_active_nodes(S0)\n",
    "    return S1_aggregated + S0_decayed\n",
    "\n",
    "\n",
    "def S_nodes_to_actors(S: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert tensor of nodes' states to a vector of actors' states.\"\"\"\n",
    "    _S = torch.clone(S)\n",
    "    _S[_S == -1 * float(\"inf\")] = 0.\n",
    "    return _S.sum(dim=0).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_nd = net_m\n",
    "net_torch = MultilayerNetworkTorch.from_mln(net_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = set()\n",
    "for actor in net_nd.get_actors():\n",
    "    if np.random.choice([0, 1], p=[0.8, 0.2]) == 1:\n",
    "        seeds.add(actor.actor_id)\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = create_states_tensor(net_torch, seeds)\n",
    "S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sn = S0\n",
    "# print(Sn)\n",
    "print(S_nodes_to_actors(Sn))\n",
    "for step in range(5):\n",
    "    Sn = simulation_step(net_torch, 0.3, protocol_AND, Sn)\n",
    "    # print(Sn)\n",
    "    print(S_nodes_to_actors(Sn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nd2",
   "language": "python",
   "name": "nd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
